## Schema registry and why it is useful

It is pretty obvious why schemas are useful when multiple **clients need to collaborate on the same data**.
They all need to know the metadata, which fields are available and what are their types.
Moreover, data storage and processing is more efficient, because we don't need to send the schema with each message and numbers can be stored in their binary representation.

It is less obvious why we may need a **central schema registry**.
Why would you want to add this complexity to your architecture?
Why not simply agree on a message schema, put it in shared library and live with that?
Distributing schemas is easy when we have few clients that we control, but it becomes challenging when we have lots of clients and some of them are by third party.
In addition to distribution, we also need to evolve these schema safely in a backwards and forwards compatible way, to allow new clients to read old data and old clients to read new data.

[Red Hat Service Registry](https://catalog.redhat.com/software/operators/detail/5ef2818e7dc79430ca5f4fd2) is based on [Apicurio Registry](https://www.apicur.io/registry), which is a schema registry for REST APIs (OpenAPI) and message schemas (AsyncAPI).
It supports pluggable storage (in-memory, Kafka, PostgreSQL), schema versioning, schema validation and provides **Java serializers/deserializers** (SerDes) for Avro, Protobuf and JSON Schema formats.
It also provides a **Maven plugin** that we can use to register schema artifacts at build time, a REST API and a web console to do CRUD operations on schema artifacts.
When migrating from Confluent registry, it is possible to enable the API translation layer and use a tool called `exportConfluent` to import existing schemas.

![](images/serdes.png)

A registered schema artifact is uniquely identified by the tuple `(groupId, artifactId, version)`.
Both `groupId` and `artifactId` and are generated by the client, while `globalId` and `contentId` are generated by the server.
The `globalId` is the unique id of an artifact version, while the `contentId` is the unique id of the artifact content.

The **serializer** exchanges the `artifactId` for a `globalId`, which is then added as record header or as payload prefix, depending on the producer configuration.
The default `artifactId` resolver strategy is the `TopicIdStrategy`, which looks for schema artifacts with the same `artifactId` as the Kafka topic, plus `-key` or `-value` suffixes.
You might want to use the `RecordIdStrategy` strategy if you have different Kafka topics with the same Avro message type.

When you scale up your application instances, there is a race condition if you let your application to register the schema at startup.
In that case, you may end up with multiple schemas with different `globalId`, but the same `contentId`.
The solution is to register the schema at build time using the Maven plugin.

The **deserializer** fetches the right schema version using the `globalId`, but you can also configure to fetch by `contentId` (Confluent default).
Setting `apicurio.registry.check-period-ms` client property we can determine the time after which a cached artifact is auto evicted and needs to be fetched again on the next record.

### Example: schema registry in action

[Deploy Streams operator and Kafka cluster](/sessions/001).
Then, we can deploy the Service Registry instance with PostgreSQL as storage system.

```sh
$ kubectl create -f sessions/003/crs
persistentvolumeclaim/my-pgsql-data created
configmap/my-pgsql-env created
configmap/my-pgsql-init created
statefulset.apps/my-pgsql-ss created
service/my-pgsql-svc created
apicurioregistry.registry.apicur.io/my-registry created

$ kubectl get po
NAME                                              READY   STATUS    RESTARTS   AGE
pod/my-cluster-entity-operator-6b68959588-698hp   3/3     Running   0          165m
pod/my-cluster-kafka-0                            1/1     Running   0          166m
pod/my-cluster-kafka-1                            1/1     Running   0          166m
pod/my-cluster-kafka-2                            1/1     Running   0          166m
pod/my-cluster-zookeeper-0                        1/1     Running   0          168m
pod/my-cluster-zookeeper-1                        1/1     Running   0          168m
pod/my-cluster-zookeeper-2                        1/1     Running   0          168m
pod/my-pgsql-ss-0                                 1/1     Running   0          8m36s
pod/my-registry-deployment-5f5fb7c786-7tj75       1/1     Running   0          53s
```

Now, we just need to tell our client application where it can find the Kafka cluster by setting the bootstrap URL and the schema registry REST endpoint.
We also need to provide the truststore location and password because we are connecting externally.

```sh
$ export BOOTSTRAP_SERVERS=$(kubectl get routes my-cluster-kafka-bootstrap -o jsonpath="{.status.ingress[0].host}"):443 \
  && export REGISTRY_URL=http://$(kubectl get apicurioregistries my-registry -o jsonpath="{.status.info.host}")/apis/registry/v2 \
  && kubectl get secret my-cluster-cluster-ca-cert -o jsonpath="{.data['ca\.p12']}" | base64 -d > /tmp/truststore.p12 \
  && export SSL_TRUSTSTORE_LOCATION="/tmp/truststore.p12" \
  && export SSL_TRUSTSTORE_PASSWORD=$(kubectl get secret my-cluster-cluster-ca-cert -o jsonpath="{.data['ca\.password']}" | base64 -d)

$ mvn clean compile exec:java -f sessions/003/kafka-avro/pom.xml -q
Producing records
Records produced
Consuming all records
Record: Hello-1663594981476
Record: Hello-1663594982041
Record: Hello-1663594982041
Record: Hello-1663594982041
Record: Hello-1663594982042
```

[Look at the code](/sessions/003/kafka-avro) to see how the schema is registered and used.
The registration happens at build time and the Maven plugin execute the following API request for every configured schema artifact.
Note that we are using the "default" group id, but you can specify a custom name.

```sh
$ curl -s -X POST -H "Content-Type: application/json" \
  -H "X-Registry-ArtifactId: my-topic-value" -H "X-Registry-ArtifactType: AVRO" \
  -d @sessions/003/kafka-avro/src/main/resources/greeting.avsc \
  $REGISTRY_URL/groups/default/artifacts?ifExists=RETURN_OR_UPDATE | jq
{
  "name": "Greeting",
  "createdBy": "",
  "createdOn": "2022-09-30T06:31:36+0000",
  "modifiedBy": "",
  "modifiedOn": "2022-09-30T06:31:36+0000",
  "id": "my-topic-value",
  "version": "1",
  "type": "AVRO",
  "globalId": 4,
  "state": "ENABLED",
  "contentId": 6
}
```

Finally, let's use the REST API to confirm that our schema was registered correctly.
We can also look at the schema content and metadata, which may be useful for debugging.

```sh
$ curl -s $REGISTRY_URL/search/artifacts | jq
{
  "artifacts": [
    {
      "id": "my-topic-value",
      "name": "Greeting",
      "createdOn": "2022-09-19T13:42:59+0000",
      "createdBy": "",
      "type": "AVRO",
      "state": "ENABLED",
      "modifiedOn": "2022-09-19T13:42:59+0000",
      "modifiedBy": ""
    }
  ],
  "count": 1
}

$ curl -s $REGISTRY_URL/groups/default/artifacts/my-topic-value | jq
{
  "type": "record",
  "name": "Greeting",
  "fields": [
    {
      "name": "Message",
      "type": "string"
    },
    {
      "name": "Time",
      "type": "long"
    }
  ]
}

$ curl -s $REGISTRY_URL/groups/default/artifacts/my-topic-value/meta | jq
{
  "name": "Greeting",
  "createdBy": "",
  "createdOn": "2022-09-19T13:42:59+0000",
  "modifiedBy": "",
  "modifiedOn": "2022-09-19T13:42:59+0000",
  "id": "my-topic-value",
  "version": "1",
  "type": "AVRO",
  "globalId": 1,
  "state": "ENABLED",
  "contentId": 1
}
```
